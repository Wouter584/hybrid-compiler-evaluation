#include <iostream>
#include <vector>
#include <chrono>
#include <cuda_runtime.h>
#include <fstream>
#include <string>

#define CHECK_CUDA(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            std::cerr << "CUDA error: " << cudaGetErrorString(err) << std::endl; \
            exit(EXIT_FAILURE); \
        } \
    } while (0)

struct C64 {
    double real;
    double imaginary;
};

__host__ __device__
C64 operator+(const C64& a, const C64& b)
{
    return C64{a.real + b.real, a.imaginary + b.imaginary};
}

__host__ __device__
C64 operator-(const C64& a, const C64& b)
{
    return C64{a.real - b.real, a.imaginary - b.imaginary};
}

__host__ __device__
C64 operator*(const C64& a, const C64& b)
{
    return C64{a.real * b.real - a.imaginary * b.imaginary,
               a.real * b.imaginary + a.imaginary * b.real};
}

__global__ void matrix_mul(C64* result, const C64* a, const C64* b, const int width, const int height) {
    const int t = blockIdx.x * blockDim.x + threadIdx.x;
    const int i = t / height;
    const int j = t % height;
    auto sum = C64{0.0, 0.0};
    for (int k = 0; k < width; ++k) {
        sum = sum + a[i * width + k] * b[k * height + j];
    }
    result[i * height + j] = sum;
}

struct BenchResult {
    int size;
    double gpu_time;
    std::string title;
};

void export_bench_results(const BenchResult* results, int count) {
    // open a file to write the results
    std::ofstream file("results/bench_results8.txt");
    if (!file.is_open()) {
        std::cerr << "Error opening file for writing results." << std::endl;
        return;
    }
    // write as follows: B1|<bench_name>|<size>|<gpu_time>
    for (int i = 0; i < count; ++i) {
        file << "B8|" << results[i].title << "|"
             << results[i].size << "|"
             << results[i].gpu_time << std::endl;
    }
    file.close();
    std::cout << "Results exported to bench_results8.txt" << std::endl;
}

const int is[] = { 1, 10, 20, 50, 100, 200 };
const int is_count = sizeof(is) / sizeof(is[0]);

int main() {
    int n = 1024;
    size_t size = n * n * sizeof(C64);
    BenchResult results[is_count];

    std::vector<C64> a(n * n), b(n * n), c(n * n, C64{0.0, 0.0});

    for (int i = 0; i < n * n; ++i) {
        a[i] = C64{i * 12345.6789, 0.0};
        b[i] = C64{0.0, i * 98765.4321};
    }

    C64 *d_a, *d_b, *d_c;
    CHECK_CUDA(cudaMalloc(&d_a, size));
    CHECK_CUDA(cudaMalloc(&d_b, size));
    CHECK_CUDA(cudaMalloc(&d_c, size));

    CHECK_CUDA(cudaMemcpy(d_a, a.data(), size, cudaMemcpyHostToDevice));
    CHECK_CUDA(cudaMemcpy(d_b, b.data(), size, cudaMemcpyHostToDevice));

    int threads_per_block = 256;
    int blocks = (n * n + threads_per_block - 1) / threads_per_block;

    for (int index = 0; index < is_count; ++index) {
        const int iters = is[index];

        auto gpu_start = std::chrono::high_resolution_clock::now();
        for (int iter = 0; iter < iters; ++iter) {
            matrix_mul<<<blocks, threads_per_block>>>(d_a, d_b, d_c, n, n);
            CHECK_CUDA(cudaDeviceSynchronize());
        }

        CHECK_CUDA(cudaMemcpy(c.data(), d_c, size, cudaMemcpyDeviceToHost));

        auto gpu_end = std::chrono::high_resolution_clock::now();
        double gpu_time = std::chrono::duration<double, std::milli>(gpu_end - gpu_start).count();


        std::cout << "Matrix size: " << n << "x" << n <<
            " - Iterations: " << iters <<
         " - GPU time: " << gpu_time << " ms" << std::endl;

        results[index].size = iters;
        results[index].gpu_time = gpu_time;
        results[index].title = std::to_string(n) + "x" + std::to_string(n) + " - " + std::to_string(iters) + " iterations";
    }
    CHECK_CUDA(cudaFree(d_a));
    CHECK_CUDA(cudaFree(d_b));
    CHECK_CUDA(cudaFree(d_c));

    export_bench_results(results, is_count);
    std::cout << "All done!" << std::endl;
    return 0;
}

